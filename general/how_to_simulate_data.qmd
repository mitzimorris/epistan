---
title: How to Write a Stan Model to Simulate Data and Why You Should
author: Mitzi Morris
format:
  html:
    theme:
      - theming/theme.scss
      - cosmo
    syntax-definitions:
      - theming/stan.xml
    highlight-style:
      light: theming/tango.theme
    code-copy: true
    code-overflow: wrap
    css: theming/quarto_styles.css
    toc: true
    toc-location: left
    grid:
      body-width: 800px
      margin-width: 200px

reference-location: margin
citation-location: margin

jupyter: python3
---

```{python}
#| echo: false
import os
import numpy as np
import pandas as pd
import json
from random import randint
from cmdstanpy import CmdStanModel, write_stan_json
# notebook display options
np.set_printoptions(precision=2)
np.set_printoptions(suppress=True)
np.set_printoptions(linewidth=200, threshold=1000)
pd.set_option('display.precision', 2)
pd.options.display.float_format = '{:.2f}'.format
pd.set_option('display.max_columns', 20)
pd.set_option('display.width', 200)
```

## Preface

This notebook demonstrates how to write a Stan program to build one or more datasets which can be used
to develop, test, and demo a Stan model.

The examples used are based on challenges faced by epidemiologist and public health officials:
how to estimate disease prevalence in the general population and subpopulations of interest
from diagnostic test data.
These models can be used for any observational dataset consisting of a per-datum
vector of categorical features and a binary outcome or response.

### Simulated Data 

By "simulated data" we mean data generated from a set of known parameter values.

### Why You Should

A Stan model infers the model parameters given the data.
The data-generating program flips the computation:
given parameters, it outputs the data according to the specified distributions.
Using a Stan program instead of data-generating script in Julia, Python, or R
ensures that the same parameterization and implementation the probability distributions
are used to generate the data and fit the model.

A correctly implemented model should be able to recover the parameters given the generated dataset.
If it can't, then either the implementation of the data-generating program does not match the model
(a programming error) or the model is fundamentally misspecified (a modeling error).
[Both programming errors and modeling errors are all too common;
eliminate all possibility of the former before trying to fix the latter.]{.aside}
This approach also allows for deliberate investigation of
model misspecification by using data-generating programs that
employ distributions and hyper-priors different from
those specified in the target model.

### How to Do It

The data-generating program is based on the Stan model.

* Parameter variable declarations and definitions in the `parameters`, `transformed parameters`, and `model` block
are either moved to the `data` block and passed in as data or defined in the `transformed data` block;
alternatively, they can be declared and defined in the `generated quantities` block.

* Sampling statements in the model block
are transposed into the generated quantities block as calls to the
[pseudorandom number generator functions](https://mc-stan.org/docs/functions-reference/conventions_for_probability_functions.html#distributions-prng)
(PRNG functions) corresponding to the sampling distributions.
The sampling statements infer the parameters given the data;
the PRNG functions generate data given the parameters.

The resulting code has no parameter variables or model block; therefore it is
more properly called a "program" rather than a model.
Nonetheless, we can build and run this program just like any other Stan model
and use Stan's [fixed-parameter sampler](https://mc-stan.org/docs/reference-manual/mcmc.html#sampling-without-parameters)
to run any number of iterations.
With each iteration, the statements in the generated quantities block will generate a complete dataset.

If the parameters are defined as data, the program will generate many draws from the same parameters,
thus demonstrating the range of behaviors compatible with a single draw or summary from the fitted model.
If the parameters are defined in the generated quantities block,
each generated dataset comes from a different set of parameters.
This facilitates investigation of the the choice of priors and hyper-priors and prior predictive distributions.
See the Stan User's Guide section on [Posterior and Prior Predictive Checks](https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html)
for more discussion.

## Best Practice:  Start Simple

Starting from a trivial model makes it easy to verify that all components
of the system are functioning properly.

### Stan's "Hello, World!" model:  `bernoulli.stan`


The CmdStan distribution provides a
["Hello, World!"](https://en.wikipedia.org/wiki/%22Hello,_World!%22_program) program
[`bernoulli.stan`](https://mc-stan.org/docs/cmdstan-guide/example_model_data.html),
(also distributed with this notebook).

```stan
data {
  int<lower=0> N;
  array[N] int<lower=0, upper=1> y;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  theta ~ beta(1, 1);  // uniform prior on interval 0,1
  y ~ bernoulli(theta);  // likelihood
}
```

This model could be used to estimate disease prevalence in the general population
given a small set of diagnostic test results under the following assumptions:

 - all individuals are alike with respect to disease susceptibility, i.e. the test data is i.i.d.
 - the test is perfectly accurate.
 - any level of disease prevalence is possible.
 

**Always Start with "Hello, World!"**

The above set of assumptions are rarely met.
A more realistic model would account for individual characteristics,
noisy tests, and what is already known about the disease.
It's tempting to start by refining the Bernoulli model to address these obvious deficits - *please don't!* </br>
As [the Wikipedia](https://en.wikipedia.org/wiki/%22Hello,_World!%22_program) explains:

> A "Hello, World!" program is often the first written by a student of a new programming language, but such a program can also be used as a sanity check to ensure that the computer software intended to compile or run source code is correctly installed, and that its operator understands how to use it.

In the Bayesian workflow, this simple Bernoulli model provides a baseline.
By fitting the model to simulated data with every successive refinement, we gain a better
understanding of the stochastic data-generating process and the ability of Stan's inference
algorithms to handle the resulting posterior geometries.
By using Stan's MCMC sampler to produce multiple simulated datasets,
we can investigate how well the model will fit different data regimes.


### Generating "Hello, World!" Data

To go with the example model `bernoulli.stan`,
the CmdStan distribution provides an example dataset `bernoulli.data.json`:

```
{
    "N" : 10,
    "y" : [0,1,0,0,0,0,0,0,0,1]
}
```

The Stan program `bernoulli_datagen.stan` generates the observed data `y` according to
a specified parameter `theta`, the probability of success.

```stan
data {
  int N;
}
generated quantities {
  real theta = beta_rng(1, 1);  // chance of success (uniform prior)
  array[N] int y;  // outcome of each bernoulli trial
  for (n in 1:N) {
    y[n] = bernoulli_rng(theta);
  }
}
```

+ The number of observations `N` is provided as data.
+ Both `theta` and `y` are generated in the `generated quantities block`.


::: {.callout-note appearance="simple"}
Instead of using a loop to populate `y`,
we could use the vectorized `bernoulli_rng` function, which would
generate the entire array `y` by creating N copies of `theta`:

```stan
y[n] = bernoulli_rng(rep_array(theta, N));
```

But in this case, a loop is both more efficient
(no need to allocate an extra array) and easier to read.
:::

Here are a few more ways we could write the data-generating program.

::: {.grid}

::: {.g-col-6}

Let parameter `theta` be fixed as data or generated in the `transformed data` block.

```stan
data {
  int N;
}
transformed data {
  real theta = beta_rng(1, 1);
}
generated quantities {
  array[N] int y;
  for (n in 1:N) {
    y[n] = bernoulli_rng(theta);
  }
}
```
:::

::: {.g-col-6}

Let the parameters to the `beta_rng` function be passed in as `real` data variables `alpha`, `beta`.

```stan
data {
  int N;
  real alpha;
  real beta;
}
transformed data {
  real theta = beta_rng(alpha, beta);
}
generated quantities {
  array[N] int y;
  for (n in 1:N) {
    y[n] = bernoulli_rng(theta);
  }
}
```
:::
:::


### Running the Data-generating Program


The data-generating program is compiled like any other Stan model.
Since there are no parameter variables and corresponding model block,
no warmup iterations are necessary.
Every iteration of this model generates a complete test dataset.

Here we run it for 10 iterations, resulting in 10 datasets.
The input data is a single value `N`, the number of bernoulli trials;
here we set this number to $100$.

```{python}
#| output: false
hello_datagen = CmdStanModel(stan_file='bernoulli_datagen.stan')
hello_data = hello_datagen.sample(data={"N":100}, chains=1, fixed_param=True, iter_sampling=10)
```

We inspect the simulated data from the first draw.
[In CmdStanPy the "." operator + variable name is equivalent to the "stan_variable" function.
In CmdStanR it is necessary to use methods from the `posterior` package to retrieve the generated data in the correct format.]{.aside}

```{python}
print(f'N {hello_data.y[0].shape[0]}\n'
      f'theta {hello_data.theta[0]:.2f}\n'
      f'y {hello_data.y[0]}')
```

We compare the generating parameter `theta` to the fraction of successes in `y`.

```{python}
for i in range(10):
    print(f'generated param: {hello_data.theta[i]:.2f} '
          f'generated dataset mean: {np.sum(hello_data.y[i])/hello_data.y[1].shape[0]}')
```

Given 100 bernoulli trials, the resulting dataset averages are not very accurate.

::: {.callout-note appearance="simple"}
The  the precision of an estimate increases as the sample size increases, according to the formula

$\text{Precision} = \frac{1}{\sqrt{N}}$

Here, $\frac{1}{\sqrt{100}} = 0.1$, which implies that the estimate is only accurate
up to $1$ decimal place.

:::



### From Stan Outputs to Stan Inputs

The input to `bernoulli.stan` consists of an integer `N` and an int array of observed results.
To create the simulated dataset, we assemble a Python dictionary with entries for
data variables `N` and `y`, using  use any draw in the sample.
Because each draw is generated according to a different value of `theta`;
we also record the corresponding generated value of theta as `theta_gen`.
[To save the Python dict as a JSON file, use the CmdStanPy function
[write_stan_json](https://mc-stan.org/cmdstanpy/api.html#write-stan-json).]{.aside}


```{python}
theta_gen = hello_data.theta[0]
sim_data = {"N" : hello_data.y[0].shape[0], "y" : hello_data.y[0].astype(int)}
sim_data
```

### Fitting the Simulated Data to the Target Model

We have copied over the bernoulli model to this notebook directory.

```{python}
#| output: false
bernoulli_model = CmdStanModel(stan_file='bernoulli.stan')
bernoulli_fit = bernoulli_model.sample(data=sim_data)
```

```{python}
#| echo: false
print("Bernoulli Fit")
bernoulli_fit.summary()
```

As noted above, 100 bernoulli trials produces a dataset
which is only accurate to $1$ decimal place.


```{python}
#| code-fold: true
print(f'data generating param theta {theta_gen}')
```

### Exercises

1. Predictive accuracy:  how much data is required to recover `theta` to 3 digit precision?

2. Prior sensitivity analysis: implement the data-generating program which lets you specify the hyper-parameters on the beta distribution; do not change the corresponding prior in model `bernoulli.stan`.  Under what circumstances does this affect the model fit?


## First Model Refinement: From Bernoulli to Binomial

Model `bernoulli.stan` takes as input the observed outsome of N Bernoulli trials;
this is more cleanly expressed using the binomial distribution:

```stan
data {
  int<lower=0> N;
  int<lower=1> trials;
  int<lower=0> successes;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  theta ~ beta(1, 1);
  successes ~ binomial(trials, theta);
}
```

The input data uses the same simulated dataset.

```{python}
sim_data['trials'] = sim_data['N']
sim_data['successes'] = sum(sim_data['y'])
```

We compile and fit the model to the simulated data.

```{python}
#| output: false
   binomial_model = CmdStanModel(stan_file='binomial.stan')
binom_fit = binomial_model.sample(data=sim_data)
```

```{python}
#| echo: false
print("Binomial Fit")
binom_fit.summary()
```

```{python}
#| echo: false
print("Bernoulli Fit")
bernoulli_fit.summary()
```

Given the same input data, the power of these models is the same
because the total number of observations are the same.
For these trivial models with no predictors, there are no measurable gains in performance.
For more complex models with more predictors and many demographic populations of interest,
the perfomance gains are significant.
For further discussion, see the
[Efficiency Tuning](https://mc-stan.org/docs/stan-users-guide/efficiency-tuning.html#exploiting-sufficient-statistics)
section of the Stan User's Guide.


## Second Model Refinement: Add Predictors, Hierarchical Parameters

When demographic information is recorded along with the test outcome,
we can build a hierarchical logistic regression model.
A linear model accounts for the combined effect of each demographic feature.
A hierarchical model allows for partial pooling of information
across all categories of each feature.

### Example: Hierarchical Binomial Model with Two Categorical Predictors

As a concrete example, consider a dataset where the test results have
categorical information on age group and racial/ethnic group for each test taker
and have been aggregated into bins according to the cross-product of age, ethnicity.
This is model `binomial_model_c2.stan`.
[When creating many models, it is challenging to come up with short but informative names.
Here the suffix `c2` is shorthand for "2 categorial predictors effects".]{.aside}


```stan
data {
  int<lower=0> N;  // strata (distinct subpopulations)
  int<lower=1> N_age, N_eth;
  array[N] int<lower=0> tests, pos_tests;
  array[N] int<lower=1, upper=N_age> age;
  array[N] int<lower=1, upper=N_eth> eth;
}
parameters {
  real alpha;   // common intercept
  real<lower=0> sigma_age, sigma_eth;  // group-level variance
  vector<multiplier=sigma_age>[N_age] beta_age;  // non-centered parameterization
  vector<multiplier=sigma_eth>[N_eth] beta_eth;
}
transformed parameters {
  vector[N] mu = alpha + beta_age[age] + beta_eth[eth];
}  
model {
  // likelihood
  pos_tests ~ binomial(tests, inv_logit(mu));
  // priors
  alpha ~ normal(0, 2.5);  // very weak
  sigma_age ~ normal(0, 2.5);
  sigma_eth ~ normal(0, 2.5);
  beta_age ~ normal(0, sigma_age);
  beta_eth ~ normal(0, sigma_eth);
}
generated quantities {
  array[N] int pos_tests_rep = binomial_rng(tests, inv_logit(mu));
}
```

This encoding uses informative variables names for each feature.
It is necessary to specify the data shape and sizes in order to
allocate storage for the input data and per-category parameters.
The number of categories per feature (`N_age`, `N_eth`)
are also used to validate the input data.
[Stan counts from 1, like a mathematician (or R programmer),
unline most programming languages, including C and Python, which count from 0]{.aside}

In the parameters block, we use Stan's [affine transform](https://mc-stan.org/docs/reference-manual/types.html#affinely-transformed-real)
to facilitate the [non-centered parameterization](https://mc-stan.org/docs/stan-users-guide/efficiency-tuning.html#hierarchical-models-and-the-non-centered-parameterization);
which decouples the dependence between the hierarchical variance `beta_age`, `beta_eth`, and elements of `beta_age` and `beta_eth`.
The choice between the centered and non-centered parameterization depends on the data.
See this excellent discussion by Michael Betancourt in his case study on
[Hierarchical Models](https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html#323_Backhanded_Complements).

In the model block, the logistic binomial outcome is computed by first
computing the linear predictor `mu`, and then computing the binomial.
It is more efficient to use the
[`binomial_logit`](https://mc-stan.org/docs/functions-reference/bounded_discrete_distributions.html#binomial-distribution-logit-parameterization)
parameterization, however, the corresponding `binomial_logit_rng` function
is not (yet) available in Stan.
As we wish to use the generated quantities block to create the `y_rep` array
use for
[posterior predictive simulations](https://mc-stan.org/docs/stan-users-guide/posterior-prediction.html#posterior-predictive-simulation-in-stan),
we compute the regression covariate `mu` in the `transformed parameters` block,
so that it can be used in both the `model` and `generated quantities` blocks.

::: {.callout-note appearance="simple"}
As the number of features grows, the above pattern becomes tedious to code -
each new feature adds two more elements to the input data block,
with corresponding coefficient vector and group-level variance parameters.
In theory, this can be generalized to a 2-D feature matrix
one row per stratum, one column per demographic feature.

```stan
  int<lower=1> N;  // number of strata
  int<lower=1> K;  // number categorical predictors
  array[N, K] int X_cats;
  ...
```

In practice, this approach is equally problematic.

* This data structure requires a corresponding K-length array of
regression coefficient vectors, but Stan doesn't support ragged arrays,
so it's necessary to use a fixed-length vector array and pad entries
which requires extensive use of array indexing.
The logic is challenging to code, modify, and maintain.

* It's difficult to keep track of the correspondance between features of interest
and array indexes by hand, therefore it's necessary to create external functions
to do the mapping from features to indices and back again.

For a small set of known co-variates, explicit, verbose code is easier to deal with.
:::


### Generating Data for Hierarchical Binomial Logistic Regression

We now proceed to rewrite this model as a data-generating program.
Model `binomial_model_c2.stan` has data variables for

* The data size and shape: number of observations, number of categories for age and ethnicity.

* The observations: demographic information, test outcomes.

We need to know the number of age, ethnicity categories before
choosing the regression co-efficients for each, as well as the total number of observations.
Therefore, as in the `bernoulli_datagen.stan` program, these are data variables
which must be specified by the user.

For this version of the model, we assume:

+ all population demographics are observed; therefore number of strata `N` is the cross-product of `N_age` and `N_eth`.

+ equal number of observations for each population demographic; therefore the number of tests per strata
is `N div N_obs`.

The `transformed data` block is used to compute `N`, the number of strata.
This is necessary because Stanâ€™s matrices, vectors, and array variables are sized
when they are declared and may not be dynamically resized; in order to enforce this
constraint, 
in order to be able to declare a series of data arrays of size `N` in the
`generated quantities` block
because in the `generated quantities` block we will declare a series of
data arrays of size `N`.
In the `generated quantities` block,
we first choose a set of values for the regression parameters,
then we generate the binomial outcomes.

The binomial model, rewritten as its data-generating counterpart is
in file `binomial_datagen_c2.stan`:

```stan
data {
  int<lower=0> N_obs;
  int<lower=1> N_age, N_eth;
}
transformed data {
  int N = N_age * N_eth;
}
generated quantities {
  // true parameters
  real sigma_age = abs(std_normal_rng());
  real sigma_eth = abs(std_normal_rng());
  real alpha = normal_rng(-1, 1);  // log-odds success baseline < 0
  vector[N_age] beta_age;
  for (n in 1:N_age) {
    beta_age[n] = normal_rng(0, sigma_age);
  }
  vector[N_eth] beta_eth;
  for (n in 1:N_eth) {
    beta_eth[n] = normal_rng(0, sigma_eth);
  }
  // data
  int N_tests = N_obs %/% N;  // integer division
  array[N] int<lower=0> tests = rep_array(N_tests, N);
  array[N] int pos_tests, sex, age, eth;
  {
    int idx = 0;  // local vars - not written to output file
    array[N] real mu;
    for (i_age in 1:N_age) {
      for (i_eth in 1:N_eth) {
        idx += 1;
        age[idx] = i_age;
        eth[idx] = i_eth;
        mu[idx] = alpha + beta_age[i_age] + beta_eth[i_eth];
        pos_tests[idx] = binomial_rng(tests[idx], inv_logit(mu[idx]));
      }
    }
  }
}
```

### Running the Data Generating Program, Fitting the Model

As above, we compile the program `binomial_datagen_c2.stan`,
specify the size and shape of the generated dataset,
and run the model for 10 iterations using a single chain.

```{python}
#| output: false
binom_datagen_c2 = CmdStanModel(stan_file='binomial_datagen_c2.stan')
datagen_size_shape = {'N_obs':3300, 'N_age':11, 'N_eth':3}
data_c2 = binom_datagen_c2.sample(data=datagen_size_shape, chains=1, fixed_param=True, iter_sampling=10)
```

We examine the per-draw generated datasets.

```{python}
for i in range(10):
    print('alpha', data_c2.alpha[i])
    print('sigma_age', data_c2.sigma_age[i], 'beta_age', data_c2.beta_age[i])
    print('sigma_eth', data_c2.sigma_eth[i], 'beta_eth', data_c2.beta_eth[i])
    print('positive tests: ', data_c2.pos_tests[i].astype(int), '\n')
```


We assemble the input data from the first draw.

```{python}
sim_data = {'N': data_c2.tests[0].shape[0],
            'N_age': data_c2.beta_age[0].shape[0],
            'N_eth': data_c2.beta_eth[0].shape[0],
    	    'age': data_c2.age[0].astype(int),
    	    'eth': data_c2.eth[0].astype(int),
            'tests': data_c2.tests[0].astype(int),
    	    'pos_tests': data_c2.pos_tests[0].astype(int)}
```

We compile and run the binomial model.

```{python}
binom_c2 = CmdStanModel(stan_file='binomial_model_c2.stan')
binom_c2_fit = binom_c2.sample(data=sim_data)
binom_c2_fit.summary()
```

### Adding a population-level predictor

When biological sex is coded as a binary variable, values {0, 1},
we can encode it as a population-level effect;
this is model `binomial_model_b1_c2.stan`.

```stan
data {
  int<lower=0> N;  // strata (distinct subpopulations)
  int<lower=1> N_age;
  int<lower=1> N_eth;
  array[N] int<lower=0> tests;
  array[N] int<lower=0> pos_tests;
  array[N] int<lower=0, upper=1> sex;
  array[N] int<lower=1, upper=N_age> age;
  array[N] int<lower=1, upper=N_eth> eth;
}
parameters {
  real alpha;   // common intercept
  real beta_sex;
  real<lower=0> sigma_age, sigma_eth;  // group-level variance
  vector<multiplier=sigma_age>[N_age] beta_age;  // non-centered parameterization
  vector<multiplier=sigma_eth>[N_eth] beta_eth;
}
transformed parameters {
  vector[N] mu = alpha + to_vector(sex) * beta_sex + beta_age[age] + beta_eth[eth];
}  
model {
  // likelihood
  pos_tests ~ binomial(tests, inv_logit(mu));
  // priors
  alpha ~ normal(0, 2.5);  // very weak
  sigma_age ~ normal(0, 2.5);
  sigma_eth ~ normal(0, 2.5);
  beta_sex ~  normal(0, 2.5);
  beta_age ~ normal(0, sigma_age);
  beta_eth ~ normal(0, sigma_eth);
}
generated quantities {
  array[N] int pos_tests_rep = binomial_rng(tests, inv_logit(mu));
}
```

**Exercise:**   Write the corresponding data generating program:  `binomial_datagen_b1_c2.stan`.
(Check your code against the program included with this case study).


## Third Refinement:  Unequal Number of Observations per Demographic

In this section, we refine the data-generating program so that we get differing
number of observations per demographic.



## Fourth Refinement:  Test Sensitivity and Specificity

The *sensitivity* of a test is its diagnositc accuracy
for individuals who have the disease.
Given random variable $Y$, the disease status,
where $1$ indicates has the disease and $0$ indicates doesn't have the disease
and random variable $Z$, the diagnostic test result,
where $1$ indicates positive result and $0$ a negative result,

$$ \textrm{sensitivity} = \textrm{Pr}[Y = 1 \mid Z = 1]. $$

The *specificity* of a test is its diagnostic accuracy
for individuals who don't have the disease.

$$ \textrm{specificity} = \textrm{Pr}[Y = 0 \mid Z = 0]. $$

To account for imperfect test sensitivity and specificity,
we compute the likelihood of observing a positive test result
based on an unobserved (latent) parameter: the true disease status
of an invididual.  A positive test result occurs when:

* the true status is '1' and the test is correct (sensitivity)
* the true status is '0' * and the test is incorrect (1 - sensitivity)

The probability of positive disease status `inv_logit(mu)` is adjusted accordingly -
since `inv_logit(mu)` is the probability of positive disease status,
the corresponding probability of negative disease status is `1 - inv_logit(mu)`.

For a test with known sensitivity and specificity passed in as data variables

```stan
data {
 ...
 real<lower=0, upper=1> sens;
 real<lower=0, upper=1> spec;
 ...
}
```

The likelihood is computed as follows.

```stan
model {
  // likelihood
  vector[N] prob_pos = inv_logit(mu);
  vector[N] prob_pos_test = prob_pos * sens + (1 - prob_pos) * (1 - spec);
  pos_tests ~ binomial(tests, prob_pos_test);
  ...
}
```
